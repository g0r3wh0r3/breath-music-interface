# project concept/goals

This page introduces the main idea of the project. 
## core idea 
### instigating/driving problem
- traditional instrument setups seem to mostly rely on hands and feet for playing instruments and controlling pedals/switches/knobs/etc. 
- that can feel clunky, physically and cognitively demanding having to multitask between playing an instrument and controlling various effects and switches with your hands 
- and these methods of control are often limited, lacking more precise and expressive control 
## what i want to explore
- what other inputs from our bodies could be used to control sound?  
- how can we create channels for more nuanced control of more parameters, in a way that feels more organic/natural? less cognitively effortful? 
## conceptual motivation 
-  Effects feel like something you add on top after the fact, not something you “play” - i want to make the control of effects feel just as much a part of/extension of the instrument 
- Overall the goal is related to expression in a way that’s not as cognitively “effortful” 
- Direct extension of physical expression 
## project concept 
There will be two parts to the setup, the sensor ([input](inputs/input.md)) and the effect that it controls ([output](outputs/output.md)).  The user should be able to map the sensor output to different effects. The first sensor we are making is a respiratory band. The user will wear the band around their belly or ribs, and as they inhale the band will stretch. The stretching of the band will generate a signal. We are starting with one sensor and hopefully will start building more to map to different effects over time. 
## technical 
should be compatible to just plug and use in place of an expression pedal, so outputs a variable resistance across a TRS jack






